#!/usr/bin/env python3
# Copyright 2020-2025 The HuggingFace Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
æ”¹è¿›ç‰ˆ - è®­ç»ƒæœ¬åœ°LLMæ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)
ä¸»è¦æ”¹è¿›: æ›´åˆç†çš„è¾“å‡ºè·¯å¾„è®¾ç½®
"""

import argparse
import os
from datetime import datetime
from pathlib import Path
from datasets import load_dataset, Dataset
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer,
)
from trl import SFTConfig, SFTTrainer
import torch
import json


def generate_output_path(base_dir, model_path, dataset_path, lora_rank=8, lora_alpha=16, custom_suffix=""):
    """
    ç”Ÿæˆåˆç†çš„è¾“å‡ºè·¯å¾„
    
    Args:
        base_dir: åŸºç¡€è¾“å‡ºç›®å½•
        model_path: æ¨¡å‹è·¯å¾„
        dataset_path: æ•°æ®é›†è·¯å¾„
        lora_rank: LoRA rank
        lora_alpha: LoRA alpha
        custom_suffix: è‡ªå®šä¹‰åç¼€
    
    Returns:
        ç”Ÿæˆçš„è¾“å‡ºè·¯å¾„
    """
    # è·å–æ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # æå–æ¨¡å‹åç§°
    model_name = Path(model_path).name
    if model_name == ".":
        model_name = Path(model_path).resolve().name
    
    # æå–æ•°æ®é›†åç§°
    dataset_name = Path(dataset_path).stem
    
    # æ„å»ºè¾“å‡ºç›®å½•åç§°
    dir_components = [
        f"sft_{model_name}",
        f"data_{dataset_name}",
        f"lora_r{lora_rank}_a{lora_alpha}",
        timestamp
    ]
    
    if custom_suffix:
        dir_components.insert(-1, custom_suffix)
    
    output_dir_name = "_".join(dir_components)
    output_path = os.path.join(base_dir, output_dir_name)
    
    return output_path


def save_training_metadata(output_dir, args, model_path, dataset_path, dataset_size):
    """
    ä¿å­˜è®­ç»ƒå…ƒæ•°æ®ï¼Œä¾¿äºåç»­è¿½è¸ª
    """
    metadata = {
        "training_info": {
            "timestamp": datetime.now().isoformat(),
            "model_path": model_path,
            "dataset_path": dataset_path,
            "dataset_size": dataset_size,
            "output_dir": output_dir
        },
        "training_args": {
            "use_lora": args.use_lora,
            "lora_rank": args.lora_rank,
            "lora_alpha": args.lora_alpha,
            "lora_dropout": args.lora_dropout,
            "max_length": args.max_length,
            "batch_size": args.batch_size,
            "gradient_accumulation_steps": args.gradient_accumulation_steps,
            "num_epochs": args.num_epochs,
            "learning_rate": args.learning_rate,
            "warmup_ratio": args.warmup_ratio
        },
        "paths": {
            "base_model": model_path,
            "dataset": dataset_path,
            "lora_weights": os.path.join(output_dir, "lora_weights") if args.use_lora else None,
            "merged_model_command": f"python merge_lora_weights.py --base_model_path {model_path} --lora_weights_path {os.path.join(output_dir, 'lora_weights')} --output_path ./merged_{Path(output_dir).name}"
        }
    }
    
    metadata_path = os.path.join(output_dir, "training_metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ è®­ç»ƒå…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")
    return metadata_path


def format_instruction_data(example):
    """
    å°†åŒ…å«instruction, input, outputçš„æ•°æ®æ ¼å¼åŒ–ä¸ºè®­ç»ƒç”¨çš„textæ ¼å¼
    """
    instruction = example.get('instruction', '')
    input_text = example.get('input', '')
    output_text = example.get('output', '')
    
    # æ„å»ºå¯¹è¯æ ¼å¼çš„prompt
    if input_text.strip():
        prompt = f"### Instruction:\n{instruction}\n\n### Input:\n{input_text}\n\n### Response:\n{output_text}"
    else:
        prompt = f"### Instruction:\n{instruction}\n\n### Response:\n{output_text}"
    
    return {"text": prompt}


def load_local_dataset(dataset_path):
    """
    åŠ è½½æœ¬åœ°æ•°æ®é›†
    """
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨è¯†åˆ«æ ¼å¼
    if dataset_path.endswith('.json'):
        dataset = load_dataset('json', data_files=dataset_path, split='train')
    elif dataset_path.endswith('.jsonl'):
        dataset = load_dataset('json', data_files=dataset_path, split='train')
    elif dataset_path.endswith('.csv'):
        dataset = load_dataset('csv', data_files=dataset_path, split='train')
    elif dataset_path.endswith('.parquet'):
        dataset = load_dataset('parquet', data_files=dataset_path, split='train')
    elif os.path.isdir(dataset_path):
        dataset = load_dataset(dataset_path, split='train')
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†æ ¼å¼: {dataset_path}")
    
    # æ ¼å¼åŒ–æ•°æ®
    dataset = dataset.map(format_instruction_data, remove_columns=dataset.column_names)
    
    return dataset


def setup_model_and_tokenizer(model_path):
    """
    è®¾ç½®æ¨¡å‹å’Œtokenizer
    """
    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True,
        padding_side="right"
    )
    
    # è®¾ç½®pad_token
    if tokenizer.pad_token is None:
        if tokenizer.eos_token is not None:
            tokenizer.pad_token = tokenizer.eos_token
        else:
            tokenizer.add_special_tokens({"pad_token": "[PAD]"})
    
    # å°è¯•ä½¿ç”¨Flash Attention 2
    attn_implementation = "eager"
    try:
        import flash_attn
        attn_implementation = "flash_attention_2"
        print("ä½¿ç”¨ Flash Attention 2 åŠ é€Ÿè®­ç»ƒ")
    except ImportError:
        print("Flash Attention 2 æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡†æ³¨æ„åŠ›å®ç°")
    
    # åŠ è½½æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True,
        attn_implementation=attn_implementation,
        device_map="auto",
    )
    
    return model, tokenizer


def setup_lora_config(r=8, lora_alpha=16, lora_dropout=0.1):
    """
    è®¾ç½®LoRAé…ç½®
    """
    from peft import LoraConfig, TaskType
    
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=r,
        lora_alpha=lora_alpha,
        lora_dropout=lora_dropout,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        bias="none",
    )
    
    return lora_config


def save_lora_model_properly(trainer, output_dir, tokenizer, base_model_path):
    """
    æ­£ç¡®ä¿å­˜LoRAæ¨¡å‹
    """
    print(f"æ­£ç¡®ä¿å­˜LoRAæ¨¡å‹åˆ°: {output_dir}")
    
    # åˆ›å»ºlora_weightsç›®å½•
    lora_weights_dir = os.path.join(output_dir, "lora_weights")
    os.makedirs(lora_weights_dir, exist_ok=True)
    
    # ä¿å­˜LoRAé€‚é…å™¨æƒé‡
    print("ä¿å­˜LoRAé€‚é…å™¨æƒé‡...")
    trainer.model.save_pretrained(lora_weights_dir)
    
    # ä¿å­˜tokenizeråˆ°ä¸»ç›®å½•
    print("ä¿å­˜tokenizer...")
    tokenizer.save_pretrained(output_dir)
    
    # éªŒè¯ä¿å­˜ç»“æœ
    adapter_config_path = os.path.join(lora_weights_dir, "adapter_config.json")
    adapter_model_files = [f for f in os.listdir(lora_weights_dir) if f.startswith('adapter_model')]
    
    if os.path.exists(adapter_config_path) and adapter_model_files:
        print("âœ… LoRAæƒé‡ä¿å­˜æˆåŠŸ")
        print(f"   é…ç½®æ–‡ä»¶: {adapter_config_path}")
        print(f"   æƒé‡æ–‡ä»¶: {adapter_model_files}")
    else:
        print("âš ï¸ LoRAæƒé‡ä¿å­˜å¯èƒ½æœ‰é—®é¢˜")
    
    return lora_weights_dir


def main():
    parser = argparse.ArgumentParser(description="æ”¹è¿›ç‰ˆ - æœ¬åœ°LLMæ¨¡å‹SFTè®­ç»ƒ")
    
    # åŸºç¡€å‚æ•°
    parser.add_argument("--model_path", type=str, default="/kpfs/model/Qwen2.5/Qwen2.5-32B-Instruct", help="æœ¬åœ°æ¨¡å‹è·¯å¾„")
    parser.add_argument("--dataset_path", type=str, default="/home/haibenben/waz/trl/data/v2x_seq_sft_thinking_builtin.json", help="æœ¬åœ°æ•°æ®é›†è·¯å¾„")
    
    # è¾“å‡ºè·¯å¾„ç›¸å…³å‚æ•°
    parser.add_argument("--base_output_dir", type=str, default="./experiments", help="åŸºç¡€è¾“å‡ºç›®å½•")
    parser.add_argument("--output_suffix", type=str, default="", help="è¾“å‡ºç›®å½•è‡ªå®šä¹‰åç¼€")
    parser.add_argument("--custom_output_dir", type=str, default="./Qwen2.5_32B_sft", help="å®Œå…¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼ˆä¼šè¦†ç›–è‡ªåŠ¨ç”Ÿæˆçš„è·¯å¾„ï¼‰")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--use_lora", action="store_true", default=True, help="æ˜¯å¦ä½¿ç”¨LoRAå¾®è°ƒ")
    parser.add_argument("--max_length", type=int, default=1024, help="æœ€å¤§åºåˆ—é•¿åº¦")
    parser.add_argument("--batch_size", type=int, default=4, help="æ¯è®¾å¤‡æ‰¹å¤§å°")
    parser.add_argument("--gradient_accumulation_steps", type=int, default=16, help="æ¢¯åº¦ç´¯ç§¯æ­¥æ•°")
    parser.add_argument("--num_epochs", type=int, default=3, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--learning_rate", type=float, default=2e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--warmup_ratio", type=float, default=0.03, help="é¢„çƒ­æ¯”ä¾‹")
    parser.add_argument("--save_steps", type=int, default=500, help="ä¿å­˜é—´éš”æ­¥æ•°")
    parser.add_argument("--logging_steps", type=int, default=10, help="æ—¥å¿—è®°å½•é—´éš”")
    parser.add_argument("--eval_steps", type=int, default=500, help="è¯„ä¼°é—´éš”æ­¥æ•°")
    parser.add_argument("--weight_decay", type=float, default=0.01, help="æƒé‡è¡°å‡")
    parser.add_argument("--lr_scheduler_type", type=str, default="cosine", help="å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹")
    parser.add_argument("--max_grad_norm", type=float, default=1.0, help="æ¢¯åº¦è£å‰ªé˜ˆå€¼")
    
    # LoRAå‚æ•°
    parser.add_argument("--lora_rank", type=int, default=8, help="LoRA rank")
    parser.add_argument("--lora_alpha", type=int, default=16, help="LoRA alpha")
    parser.add_argument("--lora_dropout", type=float, default=0.1, help="LoRA dropout")
    
    # ä¼˜åŒ–é€‰é¡¹
    parser.add_argument("--use_cpu_offload", action="store_true", help="å¯ç”¨CPUå¸è½½")
    parser.add_argument("--use_8bit_optimizer", action="store_true", help="ä½¿ç”¨8bitä¼˜åŒ–å™¨")
    
    args = parser.parse_args()
    
    # ç”Ÿæˆæˆ–ä½¿ç”¨è¾“å‡ºè·¯å¾„
    if args.custom_output_dir:
        output_dir = args.custom_output_dir
        print(f"ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•: {output_dir}")
    else:
        output_dir = generate_output_path(
            base_dir=args.base_output_dir,
            model_path=args.model_path,
            dataset_path=args.dataset_path,
            lora_rank=args.lora_rank,
            lora_alpha=args.lora_alpha,
            custom_suffix=args.output_suffix
        )
        print(f"è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    print("=== è®­ç»ƒé…ç½® ===")
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"æ•°æ®é›†è·¯å¾„: {args.dataset_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ä½¿ç”¨LoRA: {args.use_lora}")
    print(f"LoRAé…ç½®: rank={args.lora_rank}, alpha={args.lora_alpha}, dropout={args.lora_dropout}")
    print(f"è®­ç»ƒå‚æ•°: epochs={args.num_epochs}, lr={args.learning_rate}, batch_size={args.batch_size}")
    print("==================")
    
    # åŠ è½½æ•°æ®é›†
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {args.dataset_path}")
    train_dataset = load_local_dataset(args.dataset_path)
    print(f"æ•°æ®é›†å¤§å°: {len(train_dataset)}")
    print(f"æ•°æ®æ ·æœ¬ç¤ºä¾‹:\n{train_dataset[0]['text'][:200]}...")
    
    # åŠ è½½æ¨¡å‹å’Œtokenizer
    print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {args.model_path}")
    model, tokenizer = setup_model_and_tokenizer(args.model_path)
    
    # ä¿å­˜è®­ç»ƒå…ƒæ•°æ®
    save_training_metadata(output_dir, args, args.model_path, args.dataset_path, len(train_dataset))
    
    # è®¾ç½®è®­ç»ƒé…ç½®
    training_args = SFTConfig(
        output_dir=output_dir,
        bf16=True,
        gradient_checkpointing=True,
        gradient_checkpointing_kwargs={"use_reentrant": False},
        max_length=args.max_length,
        per_device_train_batch_size=args.batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        dataset_num_proc=4,
        num_train_epochs=args.num_epochs,
        learning_rate=args.learning_rate,
        warmup_ratio=args.warmup_ratio,
        save_strategy="steps",
        save_steps=args.save_steps,
        logging_steps=args.logging_steps,
        logging_dir=f"{output_dir}/logs",
        dataloader_pin_memory=False,
        remove_unused_columns=True,
        optim="paged_adamw_8bit" if args.use_8bit_optimizer else "adamw_torch",
    )
    
    # è®¾ç½®LoRAé…ç½®
    peft_config = None
    if args.use_lora:
        peft_config = setup_lora_config(
            r=args.lora_rank,
            lora_alpha=args.lora_alpha,
            lora_dropout=args.lora_dropout
        )
        print(f"âœ… ä½¿ç”¨LoRAå¾®è°ƒï¼ˆrank={args.lora_rank}, alpha={args.lora_alpha}ï¼‰")
    else:
        print("âš ï¸ ä½¿ç”¨å…¨å‚æ•°å¾®è°ƒï¼ˆæ˜¾å­˜éœ€æ±‚å¾ˆå¤§ï¼‰")
    
    # åˆ›å»ºtrainer
    trainer = SFTTrainer(
        args=training_args,
        model=model,
        train_dataset=train_dataset,
        peft_config=peft_config,
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸš€ å¼€å§‹SFTè®­ç»ƒ...")
    trainer.train()
    
    # æ­£ç¡®ä¿å­˜æ¨¡å‹
    if args.use_lora:
        print("ğŸ’¾ ä¿å­˜LoRAæ¨¡å‹...")
        lora_weights_dir = save_lora_model_properly(trainer, output_dir, tokenizer, args.model_path)
        
        print(f"\nâœ… SFTè®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ”— LoRAæƒé‡: {lora_weights_dir}")
        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥åˆå¹¶æƒé‡:")
        model_name = Path(args.model_path).name
        merged_dir = f"./merged_{Path(output_dir).name}"
        print(f"python fixed_merge_lora.py \\")
        print(f"    --base_model_path {args.model_path} \\")
        print(f"    --lora_weights_path {lora_weights_dir} \\")
        print(f"    --output_path {merged_dir}")
        
    else:
        print("ğŸ’¾ ä¿å­˜å…¨å‚æ•°æ¨¡å‹...")
        trainer.save_model()
        tokenizer.save_pretrained(output_dir)
        print(f"âœ… å…¨å‚æ•°æ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}")
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    main()
